{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 样本收集：\n",
    "\n",
    "\n",
    "## 1. 爬虫\n",
    "\n",
    "\n",
    "## 2. FFmpeg\n",
    "\n",
    "- 样本采集车 ==> 路段 ==> 视频\n",
    "\n",
    "- opencv 本质 ffmpeg\n",
    "    - 具有音视频处理(编解码+API)的开源的软件库\n",
    "    - 功能：\n",
    "        - 文件格式和编解码的转换\n",
    "        - 剪切 录制 提取 裁剪 复用\n",
    "    - 获取视频的信息：\n",
    "        - ffmpeg -i xxx.mp4\n",
    "    - 视频到图片的分解：\n",
    "        - ffmpeg -i xxx.mp4 image%d.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib3\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 载入图片网站\n",
    "url = \"https://www.imooc.com\"\n",
    "# headers = (\"User-Agent\", \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36\")\n",
    "# opener = urllib.request.build_opener()\n",
    "# opener.addheaders=[headers]\n",
    "# html = opener.open(url)\n",
    "html = urllib.request.urlopen(url).read()\n",
    "\n",
    "# 解析图片\n",
    "# 参数1：html，参数2：解析方法，参数3：编码类型\n",
    "soup = BeautifulSoup(html, \"html.parser\", from_encoding=\"utf-8\")\n",
    "\n",
    "# 获取当前img标签\n",
    "images = soup.findAll(\"img\")\n",
    "# print(images)\n",
    "\n",
    "imageName = 0\n",
    "\n",
    "for image in images:\n",
    "    link = image.get(\"src\")\n",
    "#     print(\"link = \", link)\n",
    "    link = \"http:\" + link\n",
    "#     print(\"link = \", link)\n",
    "    fileFormat = link[-3:]    # 获取当前link的最后三个字符\n",
    "    if fileFormat == \"jpg\" or fileFormat == \"png\":\n",
    "        fileSavePath = \"/Users/zhengtaizhong/Desktop/T+O/crawler/\" + str(imageName) + \".jpg\"\n",
    "        imageName = imageName +1\n",
    "        try:\n",
    "            urllib.request.urlretrieve(link, fileSavePath)    # 保存图片\n",
    "        except Exception:\n",
    "            pass\n",
    "#             print(\"faile\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像预处理 ==> 获取样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face= 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "face_xml = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "eye_xml = cv2.CascadeClassifier(\"./haarcascade_eye.xml\")\n",
    "\n",
    "image = cv2.imread(\"sinb.jpg\",1)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# cv2.imshow(\"src\", image)\n",
    "\n",
    "# 人脸检测\n",
    "faces = face_xml.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "print(\"face=\", len(faces))\n",
    "index = 0    # 要保存的图片名\n",
    "\n",
    "# 给人脸画方框，(x,y) 人脸检测的起始坐标\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "    roi_face = gray[y:y+h, x:x+w]    # 定位人脸区域，检测人眼\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    file_path = \"./roi/\" + str(index)+ \".jpg\"\n",
    "    index = index + 1\n",
    "    cv2.imwrite(file_path, roi_color)\n",
    "\n",
    "# cv2.imshow(\"dst\", image)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:%.2f 0.046875\n",
      "acc:%.2f 0.046875\n",
      "acc:%.2f 0.046875\n",
      "acc:%.2f 0.05078125\n",
      "acc:%.2f 0.053125\n",
      "acc:%.2f 0.059895832\n",
      "acc:%.2f 0.06473214\n",
      "acc:%.2f 0.068359375\n",
      "acc:%.2f 0.07118055\n",
      "acc:%.2f 0.0734375\n",
      "acc:%.2f 0.07528409\n",
      "acc:%.2f 0.078125\n",
      "acc:%.2f 0.08173077\n",
      "acc:%.2f 0.084821425\n",
      "acc:%.2f 0.0875\n",
      "acc:%.2f 0.08984375\n",
      "acc:%.2f 0.09191176\n",
      "acc:%.2f 0.09461805\n",
      "acc:%.2f 0.097039476\n",
      "acc:%.2f 0.09921875\n",
      "acc:%.2f 0.10119048\n",
      "acc:%.2f 0.10298295\n",
      "acc:%.2f 0.105298914\n",
      "acc:%.2f 0.107421875\n",
      "acc:%.2f 0.109375\n",
      "acc:%.2f 0.11177885\n",
      "acc:%.2f 0.113425925\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-967ecf81a797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m        \u001b[0mtrain_data_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m        \u001b[0mtrain_label_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m        \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_data_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_label_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m        \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_data_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_labels_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc:%.2f'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # 1 数据yale 2 准备train label-》train # 3 cnn 4 检测\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "# 15张人脸，每张人脸包含11张64x64图片，共165张图片，4097特征\n",
    "data = open('Yale_64x64.mat','rb')\n",
    "data_dict = sio.loadmat(data) \n",
    "\n",
    "train_data = data_dict['X']     # 加载训练数据\n",
    "train_label = data_dict['Y']    # 加载训练标签\n",
    "\n",
    "\n",
    "# 打乱训练：\n",
    "# 训练图片的特征/标签值，无序排列\n",
    "train_data = np.random.permutation(train_data)\n",
    "train_label = np.random.permutation(train_label)\n",
    "\n",
    "# 把一部分的训练数据作为测试数据。\n",
    "test_data = train_data[0:64]\n",
    "test_label = train_label[0:64]\n",
    "\n",
    "# 测试图片的特征/标签值，无序排列（两次随机，保证键值对X-Y对齐）\n",
    "np.random.seed(100)    # 设置随机种子\n",
    "test_data = np.random.permutation(test_data)\n",
    "np.random.seed(100)\n",
    "test_label = np.random.permutation(test_label)\n",
    "\n",
    "\n",
    "# (165, 4096) ==> (165,64,64,1), 转换数据类型，然后像素归一化[0,1]\n",
    "train_data = train_data.reshape(train_data.shape[0],64,64,1).astype(np.float32)/255\n",
    "# 构建165的训练标签\n",
    "train_labels_new = np.zeros((165,15))    # 165张图片，15个人\n",
    "\n",
    "for i in range(0,165):\n",
    "    j = int(train_label[i,0])-1    # 1-15 ==> 0~14，j为train_label的下标\n",
    "    train_labels_new[i,j] = 1      # 为什么是1 而不是 train_label[i,0]？\n",
    "\n",
    "# 同上  \n",
    "test_data_input = test_data.reshape(test_data.shape[0],64,64,1).astype(np.float32)/255\n",
    "test_labels_input = np.zeros((64,15))# 165 image 15\n",
    "\n",
    "for i in range(0,64):    # 64张测试图片\n",
    "    j = int(test_label[i,0])-1 # 1-15 0-14 \n",
    "    test_labels_input[i,j] = 1\n",
    "\n",
    "data_input = tf.placeholder(tf.float32,[None,64,64,1])\n",
    "label_input = tf.placeholder(tf.float32,[None,15])\n",
    "\n",
    "layer1 = tf.layers.conv2d(inputs=data_input,filters=32,kernel_size=2,strides=1,padding='SAME',activation=tf.nn.relu)\n",
    "layer1_pool = tf.layers.max_pooling2d(layer1,pool_size=2,strides=2)\n",
    "layer2 = tf.reshape(layer1_pool,[-1,32*32*32])\n",
    "layer2_relu = tf.layers.dense(layer2,1024,tf.nn.relu)\n",
    "output = tf.layers.dense(layer2_relu,15)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=label_input,logits=output)\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "accuracy = tf.metrics.accuracy(labels=tf.argmax(label_input,axis=1),predictions=tf.argmax(output,axis=1))[1]\n",
    "# run\n",
    "\n",
    "# run acc\n",
    "init = tf.group(tf.global_variables_initializer(),tf.local_variables_initializer())\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)    \n",
    "    for i in range(0,200):\n",
    "        train_data_input = np.array(train_data)\n",
    "        train_label_input = np.array(train_labels_new)\n",
    "        sess.run([train,loss],feed_dict={data_input:train_data_input,label_input:train_label_input})\n",
    "        acc = sess.run(accuracy,feed_dict={data_input:test_data_input,label_input:test_labels_input})\n",
    "        print('acc:%.2f',acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
